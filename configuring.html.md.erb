---
title: Configuring MySQL for PCF
owner: MySQL
---

This topic explains how to configure the MySQL for PCF service.

To configure your MySQL service, click the **MySQL for PCF** tile in the Ops Manager **Installation Dashboard**, open each pane under the **Settings** tab, and review or change the configurable settings as described in the sections below.

![Configure Settings](config-settings.png)

## <a id="az-network"></a>Assign AZs and Networks

![Configure AZs and Networks](config-az-network.png)

MySQL for PCF supports deployment to multiple availability zones (AZs).

To maximize uptime, deploy a load balancer in front of the SQL Proxy nodes. Please see the note in the [proxy](#proxy) section below. When configuring this load balancer, increase the minimum idle timeout if possible, as many load balancers are tuned for short-lived connections unsuitable for long-running database queries. See the [load balancer configuration instructions](./installing.html#load-balancer) for details.

## <a id="plans"></a>Service Plans

![Configure Service Plans](config-service-plans.png)

Service plans offer developers different versions of the MySQL service. An example is tiered service plans with that offer a range of resource limits and pricing. See [Service Plans](./service-plan.html) for how to configure one or more service plans in the **Service Plans** pane.

<p class="note"><strong>Note</strong>: You cannot deploy MySQL for PCF without at least one plan defined.</p>

## <a id="proxy"></a>Proxy

![Configure Proxy](config-proxy.png)

The proxy tier is responsible for routing connections from applications to healthy MariaDB cluster nodes, even in the event of node failure.

Applications are provided with a hostname or IP address to reach a database managed by the service. For more information, see [Application Binding](http://docs.pivotal.io/pivotalcf/devguide/services/index.html#application-binding). By default, the MySQL service will provide bound applications with the IP of the first instance in the proxy tier. Even if additional proxy instances are deployed, client connections will not be routed through them. This means the first proxy instance is a single point of failure.

<p class="note"><strong>Note</strong> In order to eliminate the first proxy instance as a single point of failure, operators must configure a load balancer to route client connections to all proxy IPs, and configure the MySQL service to give bound applications a hostname or IP address that resolves to the load balancer.</p>

#### <a id="proxy-instances"></a> Number of proxy instances cannot be reduced
Once the product is deployed with operator-configured proxy IPs, the number of proxy instances cannot be reduced, nor can the configured IPs be removed from the **Proxy IPs** field. If instead the product is initially deployed without proxy IPs, IPs added to the **Proxy IPs** field will only be used when adding additional proxy instances, scaling down is unpredictably permitted, and the first proxy instance can never be assigned an operator-configured IP.

## <a id="server"></a>MySQL Server Configuration

![Configure MySQL Server Configuration](config-servers.png)

- Disable Reverse DNS lookups

    This feature is enabled by default, and improves performance. Un-checking this option causes the MySQL servers to perform a reverse DNS lookup on each new connection. It is only necessary when restricting access by hostname, which is not required in typical MySQL for PCF installations.

- Read-Only User Password

    Activates a special user, `roadmin`, a read-only administrator. Supply a special password, to be used only by administrators who require the ability to view all of the data maintained by the MySQL for PCF installation. Leaving the field blank de-activates the read-only user.

- MySQL Start Timeout

    The minimum amount of time necessary for the MySQL process to start, in seconds. When restarting the MySQL server processes, there are conditions under which the process takes longer than expected to appear as running. This can cause parts of the system automation to assume that the process has failed to start properly, and will appear as failing in OpsManager and BOSH output. Depending on the data stored by the database, and the time represented in logs, it may be necessary to increase this beyond the default of 60 seconds.

- Replication Debug logging

    By default, the MySQL service will log events related to replication errors. Only turn off this option if error logging is causing undue strain on your logging systems.

- Server Activity Logging

    The MySQL service includes the [MariaDB Audit plugin](https://mariadb.com/kb/en/mariadb/about-the-mariadb-audit-plugin/). You can disable this plugin, or configure which [events](https://mariadb.com/kb/en/mariadb/about-the-mariadb-audit-plugin/#logging-events) are recorded. The log can be found at `/var/vcap/store/mysql_audit_logs/mysql_server_audit.log` on each VM. When enabled, the file is rotated every 100 megabytes, and 30 of the most recent files are retained.

    <p class="note"><strong>Note</strong>: Due to the sensitive nature of these logs, they are not transmitted to the syslog server.</p>

## <a id="backups"></a>Backups

![Configure Backups](config-backups.png)

See the [Backups](./backup.html) topic for instructions on configuring backups.

## <a id="advanced"></a>Advanced Options

![Configure Advanced Options](config-advanced.png)

In the **Advanced Options** pane, you can change the configuration of the following features:

- The Replication Canary, see [Monitoring the MySQL Service](monitoring-mysql.html#repcanary).

- The Interruptor, see [Monitoring the MySQL Service](monitoring-mysql.html#interruptor).

- Quota Enforcer Frequency

    By default, the Quota Enforcer polls for violators and reformers every 30 seconds. This setting, in seconds, changes how long the quota enforcer pauses between checks. If you wish to reduce the small amount of load caused by the Quota Enforcer's polling, you may increase this time period. Be aware, however, that increasing the duration may make it possible for applications to write more data than their pre-determined limit allows.

## <a id="errands"></a>Errands

Two lifecycle errands are run by default: the **broker registrar** and the **smoke test**. The broker registrar errand registers the broker with the Cloud Controller and makes the service plan public. The smoke test errand runs basic tests to validate that service instances can be created and deleted, and that applications pushed to Elastic Runtime can be bound and write to MySQL service instances. Both errands can be turned on or off on the **Lifecycle Errands** page under the **Settings** tab.

<p class="note"><strong>Note</strong>: You might also notice a <b>broker-deregistrar</b> errand. <b>Do not run this errand unless instructed to do so by Support.</b> Broker-deregistrar is a part of the automation used by Ops Manager while deleting a tile. Running this errand under any other circumstance will delete user data.</p>

## <a id="resource-config"></a>Resource Config

![Configure Resources](config-resources.png)

Use this pane to configure how many database instances can be provisioned (instance capacity) by configuring the amount of persistent disk allocated to the MySQL server nodes. The broker will provision a requested database if there is sufficient unreserved persistent disk. Use the Persistent Disk field for the MySQL Server job in the Resource Config setting page in Operations Manager. Not all persistent disk will be available for instance capacity; about 2-3 GB is reserved for service operation.

In determining how much persistent disk to make available for databases, operators should also consider that MariaDB servers require sufficient CPU, RAM, and IOPS to promptly respond to client requests for all databases.

### <a id="switch-topologies"></a> Switch Between Single and HA Topologies

To switch your MySQL service between single-node and High Availability topologies, you change instance counts in the **Resource Config** pane. The table below lists the proper instance count settings for each topology.

<table>
<tr><th>Resource</th><th>Minimal</th><th>Highly Available</th></tr>
<tr><td>MySQL Server</td><td>1</td><td>3</td></tr>
<tr><td>Proxy</td><td>1</td><td>2</td></tr>
<tr><td>Service Broker</td><td>1</td><td>1-2<sup>*</sup></td></tr>
</table>

<sup>*</sup>Routine database operations do not require two service brokers.

Single and three-node clusters are the only supported topologies. Ops Manager  allows you to set the number of **MySQL Server** instances to other values, but Pivotal recommends only one or three.

If you scale up MySQL nodes, Pivotal recommends spreading them across different Availability Zones to maximize cluster availability. An Availability Zone (AZ) is a network-distinct section of a region. For more information about Amazon AZs, see [Amazon's documentation](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html).

When you change the instance counts for a MySQL service, a top-level property is updated with the new nodes' IP addresses. As BOSH deploys, it will update the configuration and restart all of the MySQL nodes **and** the proxy nodes (to inform them of the new IP addresses as well). Restarting the nodes will cause all connections to that node to be dropped while the node restarts.

## <a id="stemcell"></a>Stemcell

Use this pane to upload the stemcell that you want the service components to run on. Find available stemcells at [Pivotal Network](http://network.pivotal.io).


